{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.15 Function To Analyze Dataset Property With Silhouette Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def analyze_problem_attributes_with_silhouette(datasets):\n",
    "    \n",
    "#     \"\"\"\n",
    "#     Display clustering results of candidate clustering algorithms considering parameters \n",
    "#     of algorithms and dataset attributes as meta data. That means the algorithms will be fed with \n",
    "#     the true parameters of the datasets, except DBSCAN and Spectral clustering whose parameters are tuned.\n",
    "    \n",
    "    \n",
    "#     Parameters: \n",
    "#     ----------\n",
    "    \n",
    "#     datasets: a list of tuples\n",
    "#         the elements of the list contains tuples. the first element of the tuple if dataset and the second element of the\n",
    "#         tuple contains a dictionary.\n",
    "        \n",
    "#         Example:\n",
    "            \n",
    "#             datasets = [\n",
    "#                        (D1, {'name': 'D1', 'n_cluster': 2}), \n",
    "#                        (D2, {'name': 'D2', 'n_cluster': 3}),  \n",
    "#                        (D3, {'name': 'D3', 'n_cluster': 5}) \n",
    "#                       ]\n",
    "        \n",
    "    \n",
    "#     Return:\n",
    "#     ------\n",
    "    \n",
    "#     None\n",
    "    \n",
    "#     \"\"\"\n",
    "    \n",
    "    \n",
    "#     for i, (D, para) in enumerate(datasets):\n",
    "#         print()\n",
    "#         print(\"===================================\")\n",
    "#         print(\"Dataset: \" + para['name'])\n",
    "#         print()\n",
    "#         silhouette_avg = []\n",
    "#         total_time = []\n",
    "#         # extract meta-data of dataset\n",
    "#         n_clusters = para['n_cluster']    \n",
    "\n",
    "# #         # kmean\n",
    "#         D_para_km = {'n_clusters':n_clusters, 'init': 'k-means++', 'algorithm': 'full'}\n",
    "#         D_result_km = display_kmean_outputs(D, D_para_km)\n",
    "#         silhouette_avg.append(np.round(metrics.silhouette_score(D[0], D_result_km['label']), 3))\n",
    "#         total_time.append(np.round(D_result_km['tot_time'], 3))\n",
    "        \n",
    "#         # dbscan\n",
    "#         D_para_dbscan, D_score_dbscan = get_parameter_dbscan(D)\n",
    "# #         print_parameters(D_para_dbscan)\n",
    "#         D_result_dbscan = display_dbscan_outputs(D, D_para_dbscan)\n",
    "#         silhouette_avg.append(np.round(metrics.silhouette_score(D[0], D_result_dbscan['labels']), 3))\n",
    "#         total_time.append(np.round(D_result_dbscan['tot_time'], 3))        \n",
    "\n",
    "#         # spectral clustering\n",
    "#         D_para_sc, D_score_sc = get_parameter_sc(D, n_comp=n_clusters)\n",
    "#         D_result_sc = display_sc_outputs(D, D_para_sc)\n",
    "#         silhouette_avg.append(np.round(metrics.silhouette_score(D[0], D_result_sc['labels']), 3))\n",
    "#         total_time.append(np.round(D_result_sc['tot_time'], 3))\n",
    "        \n",
    "#          # gmm\n",
    "#         D_para_gmm = {'n_components': n_clusters, 'covariance_type': 'full', 'init_params': 'kmeans', 'n_init': 10}\n",
    "#         D_result_gmm = display_gmm_outputs(D, D_para_gmm)\n",
    "#         silhouette_avg.append(np.round(metrics.silhouette_score(D[0], D_result_gmm['labels']), 3))\n",
    "#         total_time.append(np.round(D_result_gmm['tot_time'], 3))\n",
    "        \n",
    "#         # agglo-single\n",
    "#         D_para_single = {'n_clusters':n_clusters, 'linkage': 'single', 'affinity': 'euclidean'}\n",
    "#         D_result_single = display_agglomerative_outputs(D, D_para_single)\n",
    "#         silhouette_avg.append(np.round(metrics.silhouette_score(D[0], D_result_single['label']), 3))\n",
    "#         total_time.append(np.round(D_result_single['tot_time'], 3))\n",
    "#         # agglo-complete\n",
    "#         D_para_complete = {'n_clusters':n_clusters, 'linkage': 'complete', 'affinity': 'euclidean'}\n",
    "#         D_result_complete = display_agglomerative_outputs(D, D_para_complete)\n",
    "#         silhouette_avg.append(np.round(metrics.silhouette_score(D[0], D_result_complete['label']), 3))\n",
    "#         total_time.append(np.round(D_result_complete['tot_time'], 3))\n",
    "#         # agglo-average\n",
    "#         D_para_average = {'n_clusters':n_clusters, 'linkage': 'average', 'affinity': 'euclidean'}\n",
    "#         D_result_average = display_agglomerative_outputs(D, D_para_average)\n",
    "#         silhouette_avg.append(np.round(metrics.silhouette_score(D[0], D_result_average['label']), 3))\n",
    "#         total_time.append(np.round(D_result_average['tot_time'], 3))\n",
    "#         # agglo-ward\n",
    "#         D_para_ward = {'n_clusters':n_clusters, 'linkage': 'ward', 'affinity': 'euclidean'}\n",
    "#         D_result_ward = display_agglomerative_outputs(D, D_para_ward)\n",
    "#         silhouette_avg.append(np.round(metrics.silhouette_score(D[0], D_result_ward['label']), 3))\n",
    "#         total_time.append(np.round(D_result_ward['tot_time'], 3))\n",
    "                   \n",
    "#         # create data frames to inlcude silhouette score and time separately\n",
    "        \n",
    "#         if i == 0:\n",
    "#             df_score = pd.DataFrame(data = silhouette_avg, columns = [para['name']],\n",
    "#                               index = ['k-mean', 'agglo-single', 'agglo-complete', 'agglo_average', 'agglo-ward', 'gmm', 'dbscan', 'sc'])\n",
    "# #                               index = ['dbscan', 'sc'])\n",
    "#             df_time = pd.DataFrame(data = total_time, columns = [para['name']],\n",
    "#                                   index = ['k-mean', 'agglo-single', 'agglo-complete', 'agglo_average', 'agglo-ward', 'gmm', 'dbscan', 'sc'])\n",
    "#         else:\n",
    "#             df_score[para['name']] = silhouette_avg\n",
    "#             df_time[para['name']] = total_time\n",
    "            \n",
    "            \n",
    "    \n",
    "#     print('\\n--------------')\n",
    "#     print('Silhouette Score')\n",
    "#     print(df_score)\n",
    "    \n",
    "#     print('\\n---------------')\n",
    "#     print('Total Time')\n",
    "#     print(df_time)\n",
    "        \n",
    "#     return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_algorithms_with_true_parameters_and_display_results(datasets):\n",
    "    \n",
    "    \"\"\"\n",
    "    Display clustering results of candidate clustering algorithms considering parameters \n",
    "    of algorithms and dataset attributes as meta data. That means the algorithms will be fed with \n",
    "    the true parameters of the datasets, except DBSCAN and Spectral clustering whose parameters are tuned.\n",
    "    \n",
    "    \n",
    "    Parameters: \n",
    "    ----------\n",
    "    \n",
    "    datasets: a list of tuples\n",
    "        the elements of the list contains tuples. the first element of the tuple if dataset and the second element of the\n",
    "        tuple contains a dictionary.\n",
    "        \n",
    "        Example:\n",
    "            \n",
    "            datasets = [\n",
    "                       (D1, {'name': 'D1', 'n_cluster': 2}), \n",
    "                       (D2, {'name': 'D2', 'n_cluster': 3}),  \n",
    "                       (D3, {'name': 'D3', 'n_cluster': 5}) \n",
    "                      ]\n",
    "        \n",
    "    \n",
    "    Return:\n",
    "    ------\n",
    "    \n",
    "    None\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    for i, (D, para) in enumerate(datasets):\n",
    "        print()\n",
    "        print(\"===================================\")\n",
    "        print(\"Dataset: \" + para['name'])\n",
    "        print()\n",
    "        silhouette_avg = []\n",
    "        total_time = []\n",
    "        # extract meta-data of dataset\n",
    "        n_clusters = para['n_cluster']    \n",
    "\n",
    "#         # kmean\n",
    "        D_para_km = {'n_clusters':n_clusters, 'init': 'k-means++', 'algorithm': 'full'}\n",
    "        D_result_km = display_kmean_outputs(D, D_para_km)\n",
    "        silhouette_avg.append(np.round(metrics.silhouette_score(D[0], D_result_km['label']), 3))\n",
    "        total_time.append(np.round(D_result_km['tot_time'], 3))\n",
    "        \n",
    "        # dbscan\n",
    "        D_para_dbscan, D_score_dbscan = get_parameter_dbscan(D, display_results=False)\n",
    "#         print_parameters(D_para_dbscan)\n",
    "        D_result_dbscan = display_dbscan_outputs(D, D_para_dbscan)\n",
    "        silhouette_avg.append(np.round(metrics.silhouette_score(D[0], D_result_dbscan['labels']), 3))\n",
    "        total_time.append(np.round(D_result_dbscan['tot_time'], 3))        \n",
    "\n",
    "        # spectral clustering\n",
    "        D_para_sc, D_score_sc = get_parameter_sc(D, n_comp=n_clusters, display_results=False)\n",
    "        D_result_sc = display_sc_outputs(D, D_para_sc)\n",
    "        silhouette_avg.append(np.round(metrics.silhouette_score(D[0], D_result_sc['labels']), 3))\n",
    "        total_time.append(np.round(D_result_sc['tot_time'], 3))\n",
    "        \n",
    "         # gmm\n",
    "        D_para_gmm = {'n_components': n_clusters, 'covariance_type': 'full', 'init_params': 'kmeans', 'n_init': 10}\n",
    "        D_result_gmm = display_gmm_outputs(D, D_para_gmm)\n",
    "        silhouette_avg.append(np.round(metrics.silhouette_score(D[0], D_result_gmm['labels']), 3))\n",
    "        total_time.append(np.round(D_result_gmm['tot_time'], 3))\n",
    "        \n",
    "        # agglo-single\n",
    "        D_para_single = {'n_clusters':n_clusters, 'linkage': 'single', 'affinity': 'euclidean'}\n",
    "        D_result_single = display_agglomerative_outputs(D, D_para_single)\n",
    "        silhouette_avg.append(np.round(metrics.silhouette_score(D[0], D_result_single['label']), 3))\n",
    "        total_time.append(np.round(D_result_single['tot_time'], 3))\n",
    "        # agglo-complete\n",
    "        D_para_complete = {'n_clusters':n_clusters, 'linkage': 'complete', 'affinity': 'euclidean'}\n",
    "        D_result_complete = display_agglomerative_outputs(D, D_para_complete)\n",
    "        silhouette_avg.append(np.round(metrics.silhouette_score(D[0], D_result_complete['label']), 3))\n",
    "        total_time.append(np.round(D_result_complete['tot_time'], 3))\n",
    "        # agglo-average\n",
    "        D_para_average = {'n_clusters':n_clusters, 'linkage': 'average', 'affinity': 'euclidean'}\n",
    "        D_result_average = display_agglomerative_outputs(D, D_para_average)\n",
    "        silhouette_avg.append(np.round(metrics.silhouette_score(D[0], D_result_average['label']), 3))\n",
    "        total_time.append(np.round(D_result_average['tot_time'], 3))\n",
    "        # agglo-ward\n",
    "        D_para_ward = {'n_clusters':n_clusters, 'linkage': 'ward', 'affinity': 'euclidean'}\n",
    "        D_result_ward = display_agglomerative_outputs(D, D_para_ward)\n",
    "        silhouette_avg.append(np.round(metrics.silhouette_score(D[0], D_result_ward['label']), 3))\n",
    "        total_time.append(np.round(D_result_ward['tot_time'], 3))\n",
    "                   \n",
    "        # create data frames to inlcude silhouette score and time separately\n",
    "        \n",
    "        if i == 0:\n",
    "            df_score = pd.DataFrame(data = silhouette_avg, columns = [para['name']],\n",
    "                              index = ['k-mean', 'dbscan', 'sc', 'gmm', 'agglo-single', 'agglo-complete', 'agglo_average', 'agglo-ward'])\n",
    "#                               index = ['dbscan', 'sc'])\n",
    "            df_time = pd.DataFrame(data = total_time, columns = [para['name']],\n",
    "                             index = ['k-mean', 'dbscan', 'sc', 'gmm', 'agglo-single', 'agglo-complete', 'agglo_average', 'agglo-ward'])\n",
    "        else:\n",
    "            df_score[para['name']] = silhouette_avg\n",
    "            df_time[para['name']] = total_time\n",
    "   \n",
    "    print('\\n--------------')\n",
    "    print('Silhouette Score')\n",
    "    print(df_score)\n",
    "    \n",
    "#     print('\\n---------------')\n",
    "#     print('Total Time')\n",
    "#     print(df_time)\n",
    "        \n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def analyze_problem_attributes_with_silhouette_save(datasets):\n",
    "    \n",
    "#     \"\"\"\n",
    "#     Display clustering results of candidate clustering algorithms considering parameters \n",
    "#     of algorithms and dataset attributes as meta data. That means the algorithms will be fed with \n",
    "#     the true parameters of the datasets and fixed parameters of the algorithms.\n",
    "    \n",
    "    \n",
    "#     Parameters: \n",
    "#     ----------\n",
    "    \n",
    "#     datasets: a list of tuples\n",
    "#         the elements of the list contains tuples. the first element of the tuple if dataset and the second element of the\n",
    "#         tuple contains a dictionary.\n",
    "        \n",
    "#         Example:\n",
    "            \n",
    "#             datasets = [\n",
    "#                        (D1, {'name': 'D1', 'n_cluster': 2}), \n",
    "#                        (D2, {'name': 'D2', 'n_cluster': 3}),  \n",
    "#                        (D3, {'name': 'D3', 'n_cluster': 5}) \n",
    "#                       ]\n",
    "        \n",
    "    \n",
    "#     Return:\n",
    "#     ------\n",
    "    \n",
    "#     None\n",
    "    \n",
    "#     \"\"\"\n",
    "    \n",
    "    \n",
    "#     for i, (D, para) in enumerate(datasets):\n",
    "#         print()\n",
    "#         print(\"===================================\")\n",
    "#         print(\"Dataset: \" + para['name'])\n",
    "#         print()\n",
    "#         silhouette_avg = []\n",
    "#         total_time = []\n",
    "#         # extract meta-data of dataset\n",
    "#         n_clusters = para['n_cluster']    \n",
    "\n",
    "# #         # kmean\n",
    "#         D_para_km = {'n_clusters':n_clusters, 'init': 'k-means++', 'algorithm': 'full'}\n",
    "#         D_result_km = display_kmean_outputs_save(D, D_para_km)\n",
    "# #         silhouette_avg.append(np.round(metrics.silhouette_score(D[0], D_result_km['label']), 3))\n",
    "# #         total_time.append(np.round(D_result_km['tot_time'], 3))\n",
    "        \n",
    "# #         # agglo-single\n",
    "# #         D_para_single = {'n_clusters':n_clusters, 'linkage': 'single', 'affinity': 'euclidean'}\n",
    "# #         D_result_single = display_agglomerative_outputs(D, D_para_single)\n",
    "# #         silhouette_avg.append(np.round(metrics.silhouette_score(D[0], D_result_single['label']), 3))\n",
    "# #         total_time.append(np.round(D_result_single['tot_time'], 3))\n",
    "# #         # agglo-complete\n",
    "# #         D_para_complete = {'n_clusters':n_clusters, 'linkage': 'complete', 'affinity': 'euclidean'}\n",
    "# #         D_result_complete = display_agglomerative_outputs(D, D_para_complete)\n",
    "# #         silhouette_avg.append(np.round(metrics.silhouette_score(D[0], D_result_complete['label']), 3))\n",
    "# #         total_time.append(np.round(D_result_complete['tot_time'], 3))\n",
    "# #         # agglo-average\n",
    "# #         D_para_average = {'n_clusters':n_clusters, 'linkage': 'average', 'affinity': 'euclidean'}\n",
    "# #         D_result_average = display_agglomerative_outputs(D, D_para_average)\n",
    "# #         silhouette_avg.append(np.round(metrics.silhouette_score(D[0], D_result_average['label']), 3))\n",
    "# #         total_time.append(np.round(D_result_average['tot_time'], 3))\n",
    "# #         # agglo-ward\n",
    "# #         D_para_ward = {'n_clusters':n_clusters, 'linkage': 'ward', 'affinity': 'euclidean'}\n",
    "# #         D_result_ward = display_agglomerative_outputs(D, D_para_ward)\n",
    "# #         silhouette_avg.append(np.round(metrics.silhouette_score(D[0], D_result_ward['label']), 3))\n",
    "# #         total_time.append(np.round(D_result_ward['tot_time'], 3))\n",
    "# #         # gmm\n",
    "# #         D_para_gmm = {'n_components': n_clusters, 'covariance_type': 'full', 'init_params': 'kmeans', 'n_init': 10}\n",
    "# #         D_result_gmm = display_gmm_outputs(D, D_para_gmm)\n",
    "# #         silhouette_avg.append(np.round(metrics.silhouette_score(D[0], D_result_gmm['labels']), 3))\n",
    "# #         total_time.append(np.round(D_result_gmm['tot_time'], 3))\n",
    "\n",
    "# #         # dbscan\n",
    "# #         D_para_dbscan, D_score_dbscan = get_parameter_dbscan(D)\n",
    "# # #         print_parameters(D_para_dbscan)\n",
    "# #         D_result_dbscan = display_dbscan_outputs(D, D_para_dbscan)\n",
    "# #         silhouette_avg.append(np.round(metrics.silhouette_score(D[0], D_result_dbscan['labels']), 3))\n",
    "# #         total_time.append(np.round(D_result_dbscan['tot_time'], 3))\n",
    "        \n",
    "\n",
    "# #         # spectral clustering\n",
    "# #         D_para_sc, D_score_sc = get_parameter_sc(D, n_comp=n_clusters)\n",
    "# #         D_result_sc = display_sc_outputs(D, D_para_sc)\n",
    "# #         silhouette_avg.append(np.round(metrics.silhouette_score(D[0], D_result_sc['labels']), 3))\n",
    "# #         total_time.append(np.round(D_result_sc['tot_time'], 3))\n",
    "            \n",
    "            \n",
    "# #         # create data frames to inlcude silhouette score and time separately\n",
    "        \n",
    "# #         if i == 0:\n",
    "# #             df_score = pd.DataFrame(data = silhouette_avg, columns = [para['name']],\n",
    "# #                               index = ['k-mean', 'agglo-single', 'agglo-complete', 'agglo_average', 'agglo-ward', 'gmm', 'dbscan', 'sc'])\n",
    "# # #                               index = ['dbscan', 'sc'])\n",
    "# #             df_time = pd.DataFrame(data = total_time, columns = [para['name']],\n",
    "# #                                   index = ['k-mean', 'agglo-single', 'agglo-complete', 'agglo_average', 'agglo-ward', 'gmm', 'dbscan', 'sc'])\n",
    "# #         else:\n",
    "# #             df_score[para['name']] = silhouette_avg\n",
    "# #             df_time[para['name']] = total_time\n",
    "            \n",
    "            \n",
    "    \n",
    "# #     print('\\n--------------')\n",
    "# #     print('Silhouette Score')\n",
    "# #     print(df_score)\n",
    "    \n",
    "# #     print('\\n---------------')\n",
    "# #     print('Total Time')\n",
    "# #     print(df_time)\n",
    "        \n",
    "#     return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def effect_of_rep_red_gn_3d_dataset(n_samples, centers, noise_sd=1, features = None, algorithm='Kmean'):\n",
    "#     \"\"\"\n",
    "    \n",
    "#     Example: \n",
    "#     n_samples = [100, 100]\n",
    "#     centers = np.array([[4, 3], [4, -3]])\n",
    "#     \"\"\"\n",
    "#     # 1 Create datasets\n",
    "#     # 2 Visualize datasets\n",
    "#     # 3 Run Kmean clustering algorithm\n",
    "#     # 4 Silhouette plots\n",
    "    \n",
    "#     # 1 Create datasets\n",
    "    \n",
    "#     if features == None:\n",
    "    \n",
    "#         # a repeated column\n",
    "#         para3d_repeated_D1 = {'n_samples': n_samples,\n",
    "#                         'n_features': 3,\n",
    "#                         'centers' :centers,\n",
    "#                         'repeated':1,\n",
    "#                         'lin_combination':0,\n",
    "#                               'noise_sd': noise_sd}\n",
    "#         data3d_repeated_D1 = create_3d_datasets(para3d_repeated_D1)\n",
    "# #         data3d_repeated_D1 = create_3d_datasets(para3d_repeated_D1, reset_seed=False)\n",
    "#         # a column that is lin combination of columns\n",
    "#         para3d_linComb_D1 = {'n_samples': n_samples,\n",
    "#                         'n_features': 3,\n",
    "#                         'centers' :centers,\n",
    "#                         'repeated':0,\n",
    "#                         'lin_combination':1,\n",
    "#                              'noise_sd':noise_sd}\n",
    "#         data3d_linComb_D1 = create_3d_datasets(para3d_linComb_D1)\n",
    "# #         data3d_linComb_D1 = create_3d_datasets(para3d_linComb_D1, reset_seed=False)\n",
    "#         # a column of gaussing noise\n",
    "#         para3d_gaussianNoise_D1 = {'n_samples': n_samples,\n",
    "#                         'n_features': 3,\n",
    "#                         'centers' :centers,\n",
    "#                         'repeated':0,\n",
    "#                         'lin_combination':0, \n",
    "#                                    'noise_sd':noise_sd}\n",
    "\n",
    "#         data3d_gaussianNoise_D1 = create_3d_datasets(para3d_gaussianNoise_D1)\n",
    "# #         data3d_gaussianNoise_D1 = create_3d_datasets(para3d_gaussianNoise_D1, reset_seed=False)\n",
    "\n",
    "#         # 2 Visualize datasets\n",
    "\n",
    "#         data = [(data3d_repeated_D1, {'name': 'Repeated Column'}),\n",
    "#                     (data3d_linComb_D1, {'name': 'Linear-Combination'}),\n",
    "#                     (data3d_gaussianNoise_D1, {'name': 'Gaussain Noise'})\n",
    "#                    ]\n",
    "#         visualize_3d_datasets(data)\n",
    "\n",
    "#         # 3 Run clustering algorithm\n",
    "       \n",
    "#         if algorithm == 'Kmean':     \n",
    "#             para_km = {'n_clusters': len(centers),\n",
    "#                   'init': 'k-means++',\n",
    "#                    'algorithm': 'full'\n",
    "#                   }\n",
    "\n",
    "#             label_data3d_repeated_D1, model_km_data3d_repeated_D1 = get_cluster_label_kmean(data3d_repeated_D1[0], para_km, is_model=True)\n",
    "#             label_data3d_linComb_D1, model_km_data3d_linComb_D1 = get_cluster_label_kmean(data3d_linComb_D1[0], para_km, is_model=True)\n",
    "#             label_data3d_gaussianNoise_D1, model_km_data3d_gaussianNoise_D1 = get_cluster_label_kmean(data3d_gaussianNoise_D1[0], para_km, is_model=True)\n",
    "        \n",
    "#         elif algorithm == 'GMM': \n",
    "            \n",
    "#             para_gmm = {'n_components': len(centers),\n",
    "#                     'covariance_type': 'full',\n",
    "#                     'init_params': 'kmeans',\n",
    "#                     'n_init': 15\n",
    "#                    }\n",
    "            \n",
    "#             label_data3d_repeated_D1  = get_cluster_label_gmm(data3d_repeated_D1[0], para_gmm)\n",
    "#             label_data3d_linComb_D1  = get_cluster_label_gmm(data3d_linComb_D1[0], para_gmm)\n",
    "#             label_data3d_gaussianNoise_D1 = get_cluster_label_gmm(data3d_gaussianNoise_D1[0], para_gmm)\n",
    "#         elif algorithm == 'ASL':  \n",
    "            \n",
    "#             para_asl = {'n_clusters': len(centers),\n",
    "#                         'linkage': 'single', \n",
    "#                         'affinity': 'euclidean'\n",
    "#                       }\n",
    "            \n",
    "#             label_data3d_repeated_D1  = get_cluster_label_agglo(data3d_repeated_D1[0], para_asl)\n",
    "#             label_data3d_linComb_D1  = get_cluster_label_agglo(data3d_linComb_D1[0], para_asl)\n",
    "#             label_data3d_gaussianNoise_D1 = get_cluster_label_agglo(data3d_gaussianNoise_D1[0], para_asl)\n",
    "            \n",
    "#         elif algorithm == 'ACL': \n",
    "            \n",
    "#             para_acl = {'n_clusters': len(centers),\n",
    "#                         'linkage': 'complete', \n",
    "#                         'affinity': 'euclidean'\n",
    "#                       }\n",
    "            \n",
    "#             label_data3d_repeated_D1  = get_cluster_label_agglo(data3d_repeated_D1[0], para_acl)\n",
    "#             label_data3d_linComb_D1  = get_cluster_label_agglo(data3d_linComb_D1[0], para_acl)\n",
    "#             label_data3d_gaussianNoise_D1 = get_cluster_label_agglo(data3d_gaussianNoise_D1[0], para_acl)\n",
    "            \n",
    "#         elif algorithm == 'AAL': \n",
    "            \n",
    "#             para_aal = {'n_clusters': len(centers),\n",
    "#                         'linkage': 'average', \n",
    "#                         'affinity': 'euclidean'\n",
    "#                       }\n",
    "            \n",
    "#             label_data3d_repeated_D1  = get_cluster_label_agglo(data3d_repeated_D1[0], para_aal)\n",
    "#             label_data3d_linComb_D1  = get_cluster_label_agglo(data3d_linComb_D1[0], para_aal)\n",
    "#             label_data3d_gaussianNoise_D1 = get_cluster_label_agglo(data3d_gaussianNoise_D1[0], para_aal)\n",
    "        \n",
    "#         elif algorithm == 'AWL':  \n",
    "            \n",
    "#             para_awl = {'n_clusters': len(centers),\n",
    "#                         'linkage': 'ward', \n",
    "#                         'affinity': 'euclidean'\n",
    "#                       }\n",
    "            \n",
    "#             label_data3d_repeated_D1  = get_cluster_label_agglo(data3d_repeated_D1[0], para_awl)\n",
    "#             label_data3d_linComb_D1  = get_cluster_label_agglo(data3d_linComb_D1[0], para_awl)\n",
    "#             label_data3d_gaussianNoise_D1 = get_cluster_label_agglo(data3d_gaussianNoise_D1[0], para_awl)\n",
    "        \n",
    "#         elif algorithm == 'DBSCAN':  \n",
    "               \n",
    "#             para_dbscan_repted_D1, _ = get_parameter_dbscan(data3d_repeated_D1, eps_range=(0.1, 2), min_point_range=(3, 7), total_point=50)\n",
    "                        \n",
    "#             label_data3d_repeated_D1  = get_cluster_label_dbscan(data3d_repeated_D1[0], para_dbscan_repted_D1)\n",
    "            \n",
    "#             para_dbscan_linComb_D1, _ = get_parameter_dbscan(data3d_linComb_D1, eps_range=(0.1, 2), min_point_range=(3, 7), total_point=50)\n",
    "            \n",
    "#             label_data3d_linComb_D1  = get_cluster_label_dbscan(data3d_linComb_D1[0], para_dbscan_linComb_D1)\n",
    "            \n",
    "#             para_dbscan_gaussianNoise_D1, _ = get_parameter_dbscan(data3d_gaussianNoise_D1, eps_range=(0.1, 2), min_point_range=(3, 7), total_point=50)\n",
    "            \n",
    "#             label_data3d_gaussianNoise_D1 = get_cluster_label_dbscan(data3d_gaussianNoise_D1[0], para_dbscan_gaussianNoise_D1)\n",
    "\n",
    "#         elif algorithm == 'SC':\n",
    "            \n",
    "#             para_sc_repeated_D1, _ = get_parameter_sc(data3d_repeated_D1, n_comp=len(centers))\n",
    "#             label_data3d_repeated_D1 = get_cluster_label_sc(data3d_repeated_D1[0], para_sc_repeated_D1)\n",
    "            \n",
    "#             para_sc_linComb_D1, _ = get_parameter_sc(data3d_linComb_D1, n_comp=len(centers))\n",
    "#             label_data3d_linComb_D1 = get_cluster_label_sc(data3d_linComb_D1[0], para_sc_linComb_D1)\n",
    "        \n",
    "#             para_sc_gaussianNoise_D1, _ = get_parameter_sc(data3d_gaussianNoise_D1, n_comp=len(centers))\n",
    "#             label_data3d_gaussianNoise_D1 = get_cluster_label_sc(data3d_gaussianNoise_D1[0], para_sc_gaussianNoise_D1)\n",
    "        \n",
    "#         # 4 Silhouette plots\n",
    "#         # Repeated columns\n",
    "#         fig = plt.figure(figsize=(3*f_w,1*f_h))\n",
    "#         ax1 = fig.add_subplot(1,3, 1, projection='3d')\n",
    "#         ax2 = fig.add_subplot(1,3, 2)\n",
    "# #         ax3 = fig.add_subplot(1,4, 3)\n",
    "#         ax3 = fig.add_subplot(1,3, 3, projection='3d')\n",
    "#         plot_3d_dataset(data3d_repeated_D1[0], data3d_repeated_D1[1], ax=ax1, name=\"Repeated Column\")\n",
    "#         silhouette_plot_3d(data3d_repeated_D1[0], label_data3d_repeated_D1, ax = (ax2,ax3))\n",
    "        \n",
    "#         # A linear combination of columns\n",
    "#         fig = plt.figure(figsize=(3*f_w,1*f_h))\n",
    "#         ax1 = fig.add_subplot(1,3, 1, projection='3d')\n",
    "#         ax2 = fig.add_subplot(1,3, 2)\n",
    "# #         ax3 = fig.add_subplot(1,4, 3)\n",
    "#         ax3 = fig.add_subplot(1,3, 3, projection='3d')\n",
    "#         plot_3d_dataset(data3d_linComb_D1[0], data3d_linComb_D1[1], ax=ax1, name=\"Linear Combination\")\n",
    "#         silhouette_plot_3d(data3d_linComb_D1[0], label_data3d_linComb_D1, ax = (ax2,ax3))\n",
    "        \n",
    "#         # A gaussina noise\n",
    "#         fig = plt.figure(figsize=(3*f_w,1*f_h))\n",
    "#         ax1 = fig.add_subplot(1,3, 1, projection='3d')\n",
    "#         ax2 = fig.add_subplot(1,3, 2)\n",
    "# #         ax3 = fig.add_subplot(1,4, 3)\n",
    "#         ax3 = fig.add_subplot(1,3, 3, projection='3d')\n",
    "#         plot_3d_dataset(data3d_gaussianNoise_D1[0], data3d_gaussianNoise_D1[1], ax=ax1, name=\"Gaussina Noise\")\n",
    "#         silhouette_plot_3d(data3d_gaussianNoise_D1[0], label_data3d_gaussianNoise_D1, ax = (ax2,ax3))\n",
    "#     # check_cluster_size(label_km_3d)\n",
    "\n",
    "#     #     print(\"\\nCluster centres: Repeated\\n\")\n",
    "#     #     print(model_km_data3d_repeated_D1.cluster_centers_)\n",
    "#     #     print(\"\\nCluster centres: Linear combination\\n\")\n",
    "#     #     print(model_km_data3d_linComb_D1.cluster_centers_)\n",
    "#     #     print(\"\\nCluster centres: Gaussian Noise\\n\")\n",
    "#     #     print(model_km_data3d_gaussianNoise_D1.cluster_centers_)\n",
    "#     else:\n",
    "#         para3d_D1 = {'n_samples': n_samples,\n",
    "#                      'n_features': features,\n",
    "#                      'centers' : centers,\n",
    "# #                      'repeated':1,\n",
    "# #                      'lin_combination':0,\n",
    "# #                      'noise_sd': noise_sd\n",
    "#                     }\n",
    "        \n",
    "# #         data3d_D1 = create_3d_datasets(para3d_D1, features=3)\n",
    "#         data3d_D1 = create_3d_datasets(para3d_D1, features=3, reset_seed=False)\n",
    "#         # plot figure\n",
    "        \n",
    "#         fig = plt.figure(figsize=(3*f_w, f_h))\n",
    "        \n",
    "       \n",
    "#         ax1 = fig.add_subplot(1,3, 1, projection='3d')\n",
    "#         ax2 = fig.add_subplot(1,3, 2)\n",
    "# #         ax3 = fig.add_subplot(1,4, 3)\n",
    "#         ax3 = fig.add_subplot(1,3, 3, projection='3d')\n",
    "                \n",
    "#         plot_3d_dataset(data3d_D1[0], data3d_D1[1], ax1, 'Using make_blobs')\n",
    "#         # 3 Run Kmean clustering algorithm\n",
    "#         para_km = {'n_clusters': len(n_samples),\n",
    "#               'init': 'k-means++',\n",
    "#                'algorithm': 'full'\n",
    "#               }\n",
    "\n",
    "#         label_km_data3d_D1, model_km_data3d_D1 = get_cluster_label_kmean(data3d_D1[0], para_km, is_model=True)\n",
    "\n",
    "#         silhouette_plot_3d(data3d_D1[0], label_km_data3d_D1, ax = (ax2,ax3))\n",
    "\n",
    "        \n",
    "    \n",
    "#     return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def effect_of_rep_red_gn_4d_dataset(n_samples, centers, noise_sd=1, algorithm='Kmean', reset_seed=True):\n",
    "#     \"\"\"\n",
    "#     Return a dictionary containing data, predicted label, and silhouette score\n",
    "#     effect_of_rep_red_gn_4d_dataset\n",
    "#     Example: \n",
    "#     n_samples = [100, 100]\n",
    "#     centers = np.array([[4, 3], [4, -3]])\n",
    "#     \"\"\"\n",
    "#     # 1 Create datasets\n",
    "#     # 2 Visualize datasets\n",
    "#     # 3 Run Kmean clustering algorithm\n",
    "#     # 4 Silhouette plots\n",
    "    \n",
    "#     # 1 Create datasets\n",
    "    \n",
    "#     sil_scores = []\n",
    "#     # a repeated column\n",
    "#     para3d_repeated_D1 = {'n_samples': n_samples,\n",
    "#                     'n_features': 4,\n",
    "#                     'centers' :centers,\n",
    "#                     'repeated':1,\n",
    "#                     'lin_combination':0,\n",
    "#                           'noise_sd': noise_sd}\n",
    "    \n",
    "#     # a column that is lin combination of columns\n",
    "#     para3d_linComb_D1 = {'n_samples': n_samples,\n",
    "#                     'n_features': 4,\n",
    "#                     'centers' :centers,\n",
    "#                     'repeated':0,\n",
    "#                     'lin_combination':1,\n",
    "#                          'noise_sd':noise_sd}\n",
    "    \n",
    "#     # a column of gaussing noise\n",
    "#     para3d_gaussianNoise_D1 = {'n_samples': n_samples,\n",
    "#                     'n_features': 4,\n",
    "#                     'centers' :centers,\n",
    "#                     'repeated':0,\n",
    "#                     'lin_combination':0, \n",
    "#                                'noise_sd':noise_sd}\n",
    "#     if reset_seed:    \n",
    "#         data3d_repeated_D1 = create_4d_datasets(para3d_repeated_D1)\n",
    "#         data3d_linComb_D1 = create_4d_datasets(para3d_linComb_D1)\n",
    "#         data3d_gaussianNoise_D1 = create_4d_datasets(para3d_gaussianNoise_D1)\n",
    "#     else:\n",
    "#         data3d_repeated_D1 = create_4d_datasets(para3d_repeated_D1, reset_seed=False)\n",
    "#         data3d_linComb_D1 = create_4d_datasets(para3d_linComb_D1, reset_seed=False)\n",
    "#         data3d_gaussianNoise_D1 = create_4d_datasets(para3d_gaussianNoise_D1, reset_seed=False)\n",
    "        \n",
    "#     # 2 Visualize datasets\n",
    "\n",
    "#     data = [(data3d_repeated_D1, {'name': 'Repeated Column'}),\n",
    "#                 (data3d_linComb_D1, {'name': 'Linear-Combination'}),\n",
    "#                 (data3d_gaussianNoise_D1, {'name': 'Gaussain Noise'})\n",
    "#                ]\n",
    "# #     visualize_3d_datasets(data)\n",
    "\n",
    "#     # 3 Run clustering algorithm\n",
    "\n",
    "#     if algorithm == 'Kmean':     \n",
    "#         para_km = {'n_clusters': len(centers),\n",
    "#               'init': 'k-means++',\n",
    "#                'algorithm': 'full'\n",
    "#               }\n",
    "\n",
    "#         label_data3d_repeated_D1, model_km_data3d_repeated_D1 = get_cluster_label_kmean(data3d_repeated_D1[0], para_km, is_model=True)\n",
    "#         label_data3d_linComb_D1, model_km_data3d_linComb_D1 = get_cluster_label_kmean(data3d_linComb_D1[0], para_km, is_model=True)\n",
    "#         label_data3d_gaussianNoise_D1, model_km_data3d_gaussianNoise_D1 = get_cluster_label_kmean(data3d_gaussianNoise_D1[0], para_km, is_model=True)\n",
    "\n",
    "#     elif algorithm == 'GMM': \n",
    "\n",
    "#         para_gmm = {'n_components': len(centers),\n",
    "#                 'covariance_type': 'full',\n",
    "#                 'init_params': 'kmeans',\n",
    "#                 'n_init': 15\n",
    "#                }\n",
    "\n",
    "#         label_data3d_repeated_D1  = get_cluster_label_gmm(data3d_repeated_D1[0], para_gmm)\n",
    "#         label_data3d_linComb_D1  = get_cluster_label_gmm(data3d_linComb_D1[0], para_gmm)\n",
    "#         label_data3d_gaussianNoise_D1 = get_cluster_label_gmm(data3d_gaussianNoise_D1[0], para_gmm)\n",
    "#     elif algorithm == 'ASL':  \n",
    "\n",
    "#         para_asl = {'n_clusters': len(centers),\n",
    "#                     'linkage': 'single', \n",
    "#                     'affinity': 'euclidean'\n",
    "#                   }\n",
    "\n",
    "#         label_data3d_repeated_D1  = get_cluster_label_agglo(data3d_repeated_D1[0], para_asl)\n",
    "#         label_data3d_linComb_D1  = get_cluster_label_agglo(data3d_linComb_D1[0], para_asl)\n",
    "#         label_data3d_gaussianNoise_D1 = get_cluster_label_agglo(data3d_gaussianNoise_D1[0], para_asl)\n",
    "\n",
    "#     elif algorithm == 'ACL': \n",
    "\n",
    "#         para_acl = {'n_clusters': len(centers),\n",
    "#                     'linkage': 'complete', \n",
    "#                     'affinity': 'euclidean'\n",
    "#                   }\n",
    "\n",
    "#         label_data3d_repeated_D1  = get_cluster_label_agglo(data3d_repeated_D1[0], para_acl)\n",
    "#         label_data3d_linComb_D1  = get_cluster_label_agglo(data3d_linComb_D1[0], para_acl)\n",
    "#         label_data3d_gaussianNoise_D1 = get_cluster_label_agglo(data3d_gaussianNoise_D1[0], para_acl)\n",
    "\n",
    "#     elif algorithm == 'AAL': \n",
    "\n",
    "#         para_aal = {'n_clusters': len(centers),\n",
    "#                     'linkage': 'average', \n",
    "#                     'affinity': 'euclidean'\n",
    "#                   }\n",
    "\n",
    "#         label_data3d_repeated_D1  = get_cluster_label_agglo(data3d_repeated_D1[0], para_aal)\n",
    "#         label_data3d_linComb_D1  = get_cluster_label_agglo(data3d_linComb_D1[0], para_aal)\n",
    "#         label_data3d_gaussianNoise_D1 = get_cluster_label_agglo(data3d_gaussianNoise_D1[0], para_aal)\n",
    "\n",
    "#     elif algorithm == 'AWL':  \n",
    "\n",
    "#         para_awl = {'n_clusters': len(centers),\n",
    "#                     'linkage': 'ward', \n",
    "#                     'affinity': 'euclidean'\n",
    "#                   }\n",
    "\n",
    "#         label_data3d_repeated_D1  = get_cluster_label_agglo(data3d_repeated_D1[0], para_awl)\n",
    "#         label_data3d_linComb_D1  = get_cluster_label_agglo(data3d_linComb_D1[0], para_awl)\n",
    "#         label_data3d_gaussianNoise_D1 = get_cluster_label_agglo(data3d_gaussianNoise_D1[0], para_awl)\n",
    "\n",
    "#     elif algorithm == 'DBSCAN':  \n",
    "\n",
    "#         para_dbscan_repted_D1, _ = get_parameter_dbscan(data3d_repeated_D1, eps_range=(0.1, 2), min_point_range=(3, 7), total_point=50)\n",
    "\n",
    "#         label_data3d_repeated_D1  = get_cluster_label_dbscan(data3d_repeated_D1[0], para_dbscan_repted_D1)\n",
    "\n",
    "#         para_dbscan_linComb_D1, _ = get_parameter_dbscan(data3d_linComb_D1, eps_range=(0.1, 2), min_point_range=(3, 7), total_point=50)\n",
    "\n",
    "#         label_data3d_linComb_D1  = get_cluster_label_dbscan(data3d_linComb_D1[0], para_dbscan_linComb_D1)\n",
    "\n",
    "#         para_dbscan_gaussianNoise_D1, _ = get_parameter_dbscan(data3d_gaussianNoise_D1, eps_range=(0.1, 2), min_point_range=(3, 7), total_point=50)\n",
    "\n",
    "#         label_data3d_gaussianNoise_D1 = get_cluster_label_dbscan(data3d_gaussianNoise_D1[0], para_dbscan_gaussianNoise_D1)\n",
    "\n",
    "#     elif algorithm == 'SC':\n",
    "\n",
    "#         para_sc_repeated_D1, _ = get_parameter_sc(data3d_repeated_D1, n_comp=len(centers))\n",
    "#         label_data3d_repeated_D1 = get_cluster_label_sc(data3d_repeated_D1[0], para_sc_repeated_D1)\n",
    "\n",
    "#         para_sc_linComb_D1, _ = get_parameter_sc(data3d_linComb_D1, n_comp=len(centers))\n",
    "#         label_data3d_linComb_D1 = get_cluster_label_sc(data3d_linComb_D1[0], para_sc_linComb_D1)\n",
    "\n",
    "#         para_sc_gaussianNoise_D1, _ = get_parameter_sc(data3d_gaussianNoise_D1, n_comp=len(centers))\n",
    "#         label_data3d_gaussianNoise_D1 = get_cluster_label_sc(data3d_gaussianNoise_D1[0], para_sc_gaussianNoise_D1)\n",
    "        \n",
    "#     # 4 Silhouette plots\n",
    "#     # Repeated columns\n",
    "#     fig = plt.figure(figsize=(3*f_w,1*f_h))\n",
    "#     ax1 = fig.add_subplot(1,3, 1)       \n",
    "\n",
    "#     sil_rep = silhouette_plot_only(data3d_repeated_D1[0], label_data3d_repeated_D1, ax = ax1, show_score=True)\n",
    "\n",
    "#     # A linear combination of columns\n",
    "#     ax2 = fig.add_subplot(1,3, 2)\n",
    "#     sil_red = silhouette_plot_only(data3d_linComb_D1[0], label_data3d_linComb_D1, ax = ax2, show_score=True)\n",
    "\n",
    "#     # A gaussian noise\n",
    "#     ax3 = fig.add_subplot(1,3, 3)\n",
    "#     sil_gn = silhouette_plot_only(data3d_gaussianNoise_D1[0], label_data3d_gaussianNoise_D1, ax = ax3, show_score=True)\n",
    "    \n",
    "#     results = {'data': data,\n",
    "#                'predicted_labels': (label_data3d_repeated_D1, label_data3d_linComb_D1, label_data3d_gaussianNoise_D1),\n",
    "#                'silhouette_score': (sil_rep, sil_red, sil_gn)\n",
    "#               }\n",
    "    \n",
    "#     return results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def effect_of_rep_red_gn(n_samples, centers, features=3, noise_sd=1, algorithm='Kmean', reset_seed=True):\n",
    "    \"\"\"\n",
    "    Return a dictionary containing data, predicted label, and silhouette score\n",
    "    effect_of_rep_red_gn_4d_dataset\n",
    "    Example: \n",
    "    n_samples = [100, 100]\n",
    "    centers = np.array([[4, 3], [4, -3]])\n",
    "    \"\"\"\n",
    "    # 1 Create datasets\n",
    "    # 2 Visualize datasets\n",
    "    # 3 Run Kmean clustering algorithm\n",
    "    # 4 Silhouette plots\n",
    "    \n",
    "    # 1 Create datasets    \n",
    "    sil_scores = []\n",
    "    # a repeated column\n",
    "    para = {'n_samples': n_samples, 'n_features': features, 'centers' :centers,\n",
    "            'repeated':1, 'lin_combination':0, 'noise_sd': noise_sd}    \n",
    "    data_rep = create_3or4d_dataset(para, reset_seed=reset_seed)    \n",
    "    # a column that is lin combination of columns\n",
    "    para['repeated'] = 0\n",
    "    para['lin_combination']=1\n",
    "    data_lin = create_3or4d_dataset(para, reset_seed=reset_seed) \n",
    "    # a column of gaussing noise\n",
    "    para['repeated'] = 0\n",
    "    para['lin_combination'] = 0\n",
    "    data_gn = create_3or4d_dataset(para, reset_seed=reset_seed) \n",
    "    # 2 Visualize datasets\n",
    "    data = [(data_rep, {'name': 'Repeated Column'}),\n",
    "            (data_lin, {'name': 'Linear-Combination'}),\n",
    "            (data_gn, {'name': 'Gaussain Noise'})]\n",
    "    if features == 3:\n",
    "        visualize_3d_datasets(data)\n",
    "    # 3 Run clustering algorithm\n",
    "    # By default, we choose single linkage which will be changed later\n",
    "    para_agglo = {'n_clusters': len(centers), 'linkage': 'single', \n",
    "                'affinity': 'euclidean'}\n",
    "    if algorithm == 'Kmean':     \n",
    "        para_km = {'n_clusters': len(centers), 'init': 'k-means++', 'algorithm': 'full'}\n",
    "        label_rep, _ = get_cluster_label_kmean(data_rep[0], para_km, is_model=True)\n",
    "        label_lin, _ = get_cluster_label_kmean(data_lin[0], para_km, is_model=True)\n",
    "        label_gn, _ = get_cluster_label_kmean(data_gn[0], para_km, is_model=True)\n",
    "    elif algorithm == 'GMM':\n",
    "        para_gmm = {'n_components': len(centers), 'covariance_type': 'full',\n",
    "                'init_params': 'kmeans', 'n_init': 15}\n",
    "        label_rep  = get_cluster_label_gmm(data_rep[0], para_gmm)\n",
    "        label_lin  = get_cluster_label_gmm(data_lin[0], para_gmm)\n",
    "        label_gn = get_cluster_label_gmm(data_gn[0], para_gmm)        \n",
    "    elif algorithm == 'DBSCAN':  \n",
    "        para_dbscan_rep, _ = get_parameter_dbscan(data_rep, eps_range, min_point_range, total_point, display_results=False)\n",
    "        label_rep  = get_cluster_label_dbscan(data_rep[0], para_dbscan_rep)\n",
    "        para_dbscan_lin, _ = get_parameter_dbscan(data_lin, eps_range, min_point_range, total_point, display_results=False)\n",
    "        label_lin  = get_cluster_label_dbscan(data_lin[0], para_dbscan_lin)\n",
    "        para_dbscan_gn, _ = get_parameter_dbscan(data_gn, eps_range, min_point_range, total_point, display_results=False)\n",
    "        label_gn = get_cluster_label_dbscan(data_gn[0], para_dbscan_gn)\n",
    "    elif algorithm == 'SC':\n",
    "        para_sc_rep, _ = get_parameter_sc(data_rep, n_comp=len(centers), display_results=False)\n",
    "        label_rep = get_cluster_label_sc(data_rep[0], para_sc_rep)\n",
    "        para_sc_lin, _ = get_parameter_sc(data_lin, n_comp=len(centers), display_results=False)\n",
    "        label_lin = get_cluster_label_sc(data_lin[0], para_sc_lin)\n",
    "        para_sc_gn, _ = get_parameter_sc(data_gn, n_comp=len(centers), display_results=False)\n",
    "        label_gn = get_cluster_label_sc(data_gn[0], para_sc_gn)\n",
    "    elif algorithm == 'ASL':  \n",
    "        para_agglo['linkage'] = 'single'\n",
    "#         label_rep  = get_cluster_label_agglo(data_rep[0], para_asl)\n",
    "#         label_lin  = get_cluster_label_agglo(data_lin[0], para_asl)\n",
    "#         label_gn = get_cluster_label_agglo(data_gn[0], para_asl)\n",
    "    elif algorithm == 'ACL': \n",
    "        para_agglo['linkage'] = 'complete'\n",
    "    elif algorithm == 'AAL': \n",
    "        para_agglo['linkage'] = 'average'\n",
    "    elif algorithm == 'AWL':  \n",
    "        para_agglo['linkage'] = 'ward'        \n",
    "    # if it is one of agglomerative then get the label    \n",
    "    if algorithm == 'ASL' or algorithm == 'ACL' or algorithm == 'AAL' or algorithm == 'AWL':\n",
    "        label_rep  = get_cluster_label_agglo(data_rep[0], para_agglo)\n",
    "        label_lin  = get_cluster_label_agglo(data_lin[0], para_agglo)\n",
    "        label_gn = get_cluster_label_agglo(data_gn[0], para_agglo)    \n",
    "        \n",
    "    # 4 Silhouette plots\n",
    "    # Repeated columns\n",
    "    fig = plt.figure(figsize=(3*f_w,1*f_h))\n",
    "    ax1 = fig.add_subplot(1,3, 1)\n",
    "    \n",
    "#     print(\"label_rep: \\n\", label_rep)\n",
    "    \n",
    "    sil_rep = silhouette_plot_only(data_rep[0], label_rep, ax = ax1, show_score=True)\n",
    "    # A linear combination of columns\n",
    "    ax2 = fig.add_subplot(1,3, 2)\n",
    "    sil_lin = silhouette_plot_only(data_lin[0], label_lin, ax = ax2, show_score=True)\n",
    "    # A gaussian noise\n",
    "    ax3 = fig.add_subplot(1,3, 3)\n",
    "    sil_gn = silhouette_plot_only(data_gn[0], label_gn, ax = ax3, show_score=True)    \n",
    "    results = {'data': data,\n",
    "               'predicted_labels': (label_rep, label_lin, label_gn),\n",
    "               'silhouette_score': (sil_rep, sil_lin, sil_gn)\n",
    "              }    \n",
    "    return results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_3d_dataset_one(data, algorithm='Kmean'):\n",
    "    \"\"\"\n",
    "    Return the name of the algorithm, cluster labels and silhouette score \n",
    "    and plot results of the given clustering algorithm. \n",
    "    \n",
    "    \n",
    "    data = X, y\n",
    "    \n",
    "    algorithm: a string \n",
    "        It represents the name of a clustering algorithm to be used for creating results.\n",
    "    \n",
    "    \"\"\"\n",
    "    # 1 Create datasets\n",
    "    # 2 Visualize datasets\n",
    "    # 3 Run Kmean clustering algorithm\n",
    "    # 4 Silhouette plots\n",
    "    \n",
    "    # 1 Create datasets\n",
    "    \n",
    "    X, y = data\n",
    "        \n",
    "    n_clusters = len(np.unique(y))   \n",
    "        \n",
    "\n",
    "    # 2 Visualize datasets\n",
    "\n",
    "    fig = plt.figure(figsize=(3*f_w, 3*f_h))\n",
    "    plt.subplots_adjust(top=0.95, bottom=0.08, left=0.10, right=0.95, hspace=0.4,\n",
    "                        wspace=0.35)\n",
    "\n",
    "    plt.subplot(3, 3, 1)\n",
    "    plot_dataset((data[0][:, (0,1)], data[1]), axis_name=('X', 'Y'))\n",
    "\n",
    "    plt.subplot(3, 3, 2)\n",
    "    plot_dataset((data[0][:, (1,2)], data[1]), axis_name=('Y', 'Z'))\n",
    "\n",
    "    plt.subplot(3, 3, 3)\n",
    "    plot_dataset((data[0][:, (0,2)], data[1]), axis_name=('X', 'Z'))\n",
    "\n",
    "    # 3 Run clustering algorithm\n",
    "\n",
    "    if algorithm == 'Kmean':     \n",
    "        para_km = {'n_clusters': n_clusters,\n",
    "              'init': 'k-means++',\n",
    "               'algorithm': 'full'\n",
    "              }\n",
    "\n",
    "        label_data3d, model_km_data3d = get_cluster_label_kmean(data[0], para_km, is_model=True)\n",
    "#         label_data3d_linComb_D1, model_km_data3d_linComb_D1 = get_cluster_label_kmean(data3d_linComb_D1[0], para_km, is_model=True)\n",
    "#         label_data3d_gaussianNoise_D1, model_km_data3d_gaussianNoise_D1 = get_cluster_label_kmean(data3d_gaussianNoise_D1[0], para_km, is_model=True)\n",
    "\n",
    "    elif algorithm == 'GMM': \n",
    "\n",
    "        para_gmm = {'n_components': n_clusters,\n",
    "                'covariance_type': 'full',\n",
    "                'init_params': 'kmeans',\n",
    "                'n_init': 15\n",
    "               }\n",
    "\n",
    "        label_data3d  = get_cluster_label_gmm(data[0], para_gmm)\n",
    "#         label_data3d_linComb_D1  = get_cluster_label_gmm(data3d_linComb_D1[0], para_gmm)\n",
    "#         label_data3d_gaussianNoise_D1 = get_cluster_label_gmm(data3d_gaussianNoise_D1[0], para_gmm)\n",
    "    elif algorithm == 'ASL':  \n",
    "\n",
    "        para_asl = {'n_clusters': n_clusters,\n",
    "                    'linkage': 'single', \n",
    "                    'affinity': 'euclidean'\n",
    "                  }\n",
    "\n",
    "        label_data3d  = get_cluster_label_agglo(data[0], para_asl)\n",
    "#         label_data3d_linComb_D1  = get_cluster_label_agglo(data3d_linComb_D1[0], para_asl)\n",
    "#         label_data3d_gaussianNoise_D1 = get_cluster_label_agglo(data3d_gaussianNoise_D1[0], para_asl)\n",
    "\n",
    "    elif algorithm == 'ACL': \n",
    "\n",
    "        para_acl = {'n_clusters': n_clusters,\n",
    "                    'linkage': 'complete', \n",
    "                    'affinity': 'euclidean'\n",
    "                  }\n",
    "\n",
    "        label_data3d  = get_cluster_label_agglo(data[0], para_acl)\n",
    "#         label_data3d_linComb_D1  = get_cluster_label_agglo(data3d_linComb_D1[0], para_acl)\n",
    "#         label_data3d_gaussianNoise_D1 = get_cluster_label_agglo(data3d_gaussianNoise_D1[0], para_acl)\n",
    "\n",
    "    elif algorithm == 'AAL': \n",
    "\n",
    "        para_aal = {'n_clusters': n_clusters,\n",
    "                    'linkage': 'average', \n",
    "                    'affinity': 'euclidean'\n",
    "                  }\n",
    "\n",
    "        label_data3d  = get_cluster_label_agglo(data[0], para_aal)\n",
    "#         label_data3d_linComb_D1  = get_cluster_label_agglo(data3d_linComb_D1[0], para_aal)\n",
    "#         label_data3d_gaussianNoise_D1 = get_cluster_label_agglo(data3d_gaussianNoise_D1[0], para_aal)\n",
    "\n",
    "    elif algorithm == 'AWL':  \n",
    "\n",
    "        para_awl = {'n_clusters': n_clusters,\n",
    "                    'linkage': 'ward', \n",
    "                    'affinity': 'euclidean'\n",
    "                  }\n",
    "\n",
    "        label_data3d  = get_cluster_label_agglo(data[0], para_awl)\n",
    "#         label_data3d_linComb_D1  = get_cluster_label_agglo(data3d_linComb_D1[0], para_awl)\n",
    "#         label_data3d_gaussianNoise_D1 = get_cluster_label_agglo(data3d_gaussianNoise_D1[0], para_awl)\n",
    "\n",
    "    elif algorithm == 'DBSCAN':  \n",
    "\n",
    "        para_dbscan_repted_D1, _ = get_parameter_dbscan(data, eps_range=(0.1, 2), min_point_range=(3, 7), total_point=50)\n",
    "\n",
    "        label_data3d  = get_cluster_label_dbscan(data[0], para_dbscan_repted_D1)\n",
    "\n",
    "#         para_dbscan_linComb_D1, _ = get_parameter_dbscan(data3d_linComb_D1, eps_range=(0.1, 2), min_point_range=(3, 7), total_point=50)\n",
    "\n",
    "#         label_data3d_linComb_D1  = get_cluster_label_dbscan(data3d_linComb_D1[0], para_dbscan_linComb_D1)\n",
    "\n",
    "#         para_dbscan_gaussianNoise_D1, _ = get_parameter_dbscan(data3d_gaussianNoise_D1, eps_range=(0.1, 2), min_point_range=(3, 7), total_point=50)\n",
    "\n",
    "#         label_data3d_gaussianNoise_D1 = get_cluster_label_dbscan(data3d_gaussianNoise_D1[0], para_dbscan_gaussianNoise_D1)\n",
    "\n",
    "    elif algorithm == 'SC':\n",
    "\n",
    "        para_sc_repeated_D1, _ = get_parameter_sc(data, n_comp=n_clusters)\n",
    "        label_data3d = get_cluster_label_sc(data[0], para_sc_repeated_D1)\n",
    "\n",
    "#         para_sc_linComb_D1, _ = get_parameter_sc(data3d_linComb_D1, n_comp=len(centers))\n",
    "#         label_data3d_linComb_D1 = get_cluster_label_sc(data3d_linComb_D1[0], para_sc_linComb_D1)\n",
    "\n",
    "#         para_sc_gaussianNoise_D1, _ = get_parameter_sc(data3d_gaussianNoise_D1, n_comp=len(centers))\n",
    "#         label_data3d_gaussianNoise_D1 = get_cluster_label_sc(data3d_gaussianNoise_D1[0], para_sc_gaussianNoise_D1)\n",
    "        \n",
    "    # 4 Silhouette plots\n",
    "    \n",
    "    ax4 = fig.add_subplot(3, 3, 4, projection='3d')\n",
    "    plot_3d_dataset(data[0], data[1], ax=ax4, name='Original')\n",
    "\n",
    "    ax5 = fig.add_subplot(3, 3, 5)\n",
    "    sil_score = silhouette_plot_only(data[0], label_data3d, ax=ax5)\n",
    "\n",
    "    ax6 = fig.add_subplot(3, 3, 6, projection='3d')\n",
    "    plot_3d_dataset(data[0], label_data3d, ax=ax6, name='Clustered')\n",
    "\n",
    "    plt.subplot(3, 3, 7)\n",
    "    plot_dataset((data[0][:, (0,1)], label_data3d), axis_name=('X', 'Y'))\n",
    "\n",
    "    plt.subplot(3, 3, 8)\n",
    "    plot_dataset((data[0][:, (1,2)], label_data3d), axis_name=('Y', 'Z'))\n",
    "\n",
    "    plt.subplot(3, 3, 9)\n",
    "    plot_dataset((data[0][:, (0,2)], label_data3d), axis_name=('X', 'Z'))\n",
    "\n",
    "    \n",
    "#     # Repeated columns\n",
    "#     ax1 = fig.add_subplot(1,3, 1, projection='3d')\n",
    "#     ax2 = fig.add_subplot(1,3, 2)\n",
    "# #         ax3 = fig.add_subplot(1,4, 3)\n",
    "#     ax3 = fig.add_subplot(1,3, 3, projection='3d')\n",
    "#     plot_3d_dataset(data3d_repeated_D1[0], data3d_repeated_D1[1], ax=ax1, name=\"Repeated Column\")\n",
    "#     silhouette_plot_3d(data3d_repeated_D1[0], label_data3d_repeated_D1, ax = (ax2,ax3))\n",
    "\n",
    "#     # A linear combination of columns\n",
    "#     fig = plt.figure(figsize=(3*f_w,1*f_h))\n",
    "#     ax1 = fig.add_subplot(1,3, 1, projection='3d')\n",
    "#     ax2 = fig.add_subplot(1,3, 2)\n",
    "# #         ax3 = fig.add_subplot(1,4, 3)\n",
    "#     ax3 = fig.add_subplot(1,3, 3, projection='3d')\n",
    "#     plot_3d_dataset(data3d_linComb_D1[0], data3d_linComb_D1[1], ax=ax1, name=\"Linear Combination\")\n",
    "#     silhouette_plot_3d(data3d_linComb_D1[0], label_data3d_linComb_D1, ax = (ax2,ax3))\n",
    "\n",
    "#     # A gaussina noise\n",
    "#     fig = plt.figure(figsize=(3*f_w,1*f_h))\n",
    "#     ax1 = fig.add_subplot(1,3, 1, projection='3d')\n",
    "#     ax2 = fig.add_subplot(1,3, 2)\n",
    "# #         ax3 = fig.add_subplot(1,4, 3)\n",
    "#     ax3 = fig.add_subplot(1,3, 3, projection='3d')\n",
    "#     plot_3d_dataset(data3d_gaussianNoise_D1[0], data3d_gaussianNoise_D1[1], ax=ax1, name=\"Gaussina Noise\")\n",
    "#     silhouette_plot_3d(data3d_gaussianNoise_D1[0], label_data3d_gaussianNoise_D1, ax = (ax2,ax3))\n",
    "    print(\"Number of smaples in each clusters: \\n\", check_cluster_size(label_data3d))\n",
    "    \n",
    "    return  algorithm, label_data3d, sil_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
