{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Defined Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.1 Function to Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # ==================================================================================\n",
    "\n",
    "# def synthetic_data_new(n_sample = np.array([5, 5]),\n",
    "#                        n_feature = 2,\n",
    "#                        cluster_mean = np.array([[[-4], [3]], [[4], [-5]]]),\n",
    "# #                   cluster_mean = np.array([[-4, 3], [4,-5]]), \n",
    "#                        cluster_cov = np.array([[[0.5,0], \n",
    "#                                                 [0,0.5]], \n",
    "#                                                [[0.5,0], [0,0.5]]\n",
    "#                                               ]),\n",
    "#                        overlap = 1,\n",
    "#                        n_seed=seed_num):\n",
    "    \n",
    "    \n",
    "#     \"\"\" \n",
    "#     Return a tuple of normally distributed 2D random features vectors and \n",
    "#     labels vectors identifying samples of different clusters\n",
    "    \n",
    "    \n",
    "#     Parameters:\n",
    "#     ----------\n",
    "    \n",
    "#     n_sample: a list of integer\n",
    "    \n",
    "#         Each element of the it represents the number of samples for a cluster\n",
    "        \n",
    "#     n_feature: a scalar\n",
    "    \n",
    "#         It represents the size of feature space, feature dimension\n",
    "        \n",
    "#     cluster_mean: an array\n",
    "    \n",
    "#         It holds the mean of clusters of individual clusters in a dataset\n",
    "    \n",
    "#     cluster_cov: an array\n",
    "    \n",
    "#         It holds the covarance matrix of individual clusters in a dataset\n",
    "        \n",
    "#     overlap: a scalar\n",
    "    \n",
    "#         It represents how close the clusters are from each other. Small value \n",
    "#         makes them come close to each other and higher value >= 1 puts them \n",
    "#         farther apart from each other.\n",
    "        \n",
    "#     n_seed: an integer\n",
    "    \n",
    "#         It is used to generate the same samples\n",
    "        \n",
    "        \n",
    "#     Return:\n",
    "#     ------\n",
    "    \n",
    "#     Y, l: a tuple\n",
    "    \n",
    "#         Y is a 2 dimensional array of shape (n_samples, n_attributes) which contains the \n",
    "#         bivariate normally distributed random numbers and l is a one dimensional array \n",
    "#         of shape (n_samples) representing the cluster labels of individual points. \n",
    "    \n",
    "    \n",
    "    \n",
    "#     Acknowledgement: \n",
    "#         I would like to thank author(s) to share their codes. \n",
    "#         Codes for this function are taken from following link and modified for our purposes:\n",
    "    \n",
    "#     https://peterroelants.github.io/posts/multivariate-normal-primer/\n",
    "    \n",
    "    \n",
    "#     \"\"\"\n",
    "\n",
    "    \n",
    "#     np.random.seed(seed_num)\n",
    "    \n",
    "    \n",
    "# #     cluster_mean = cluster_mean.T * overlap\n",
    "    \n",
    "    \n",
    "#     for clu in range(len(n_sample)):\n",
    "#         # Create Lower Triangular Matrix\n",
    "#         L = np.linalg.cholesky(cluster_cov[clu])\n",
    "#         # Sample X from standard normal\n",
    "#         X = np.random.normal(size=(n_feature, n_sample[clu])) # feature x n_sample_per_cluster\n",
    "#         # Apply affine transformation\n",
    "#         features = L.dot(X) + cluster_mean[clu] \n",
    "#         label = np.repeat(a = clu, repeats = n_sample[clu])        \n",
    "#          # concatinate data with labels\n",
    "#         if clu == 0:\n",
    "#             Y = features.T # n x n_features\n",
    "#             l = label\n",
    "#         else:\n",
    "#             Y = np.concatenate((Y, features.T), axis=0)\n",
    "#             l = np.concatenate((l, label), axis = 0)\n",
    "\n",
    "#      # shuffle data\n",
    "#     n_row, n_column = Y.shape\n",
    "    \n",
    "# #     shuffle_index = np.random.randint(low=0, high=n_row+, size=n_row)\n",
    "    \n",
    "#     shuffle_index = np.random.choice(range(0, n_row), size=n_row, replace=False) \n",
    "#     Y = Y[shuffle_index,:]\n",
    "#     l = l[shuffle_index,]\n",
    "    \n",
    "\n",
    "#     return Y, l\n",
    "\n",
    "\n",
    "\n",
    "# ==================================================================================\n",
    "\n",
    "# ==================================================================================\n",
    "\n",
    "# def synthetic_data(para, return_dataset_properties=False):\n",
    "\n",
    "#     \"\"\" \n",
    "    \n",
    "#     Return a tuple of normally distributed 2D random features vectors and \n",
    "#     labels vectors identifying samples of different clusters\n",
    "    \n",
    "    \n",
    "#     Parameters:\n",
    "#     ----------\n",
    "    \n",
    "#     para: a dictionary\n",
    "    \n",
    "#         The dictionary contains following keys as dataset parameters:\n",
    "        \n",
    "#         n_clusters: a scalar\n",
    "#             It represents the number of cluster in the dataaset\n",
    "    \n",
    "#         n_sample: a list of integer\n",
    "\n",
    "#             Each element of it represents the number of samples in a cluster\n",
    "\n",
    "#         n_feature: a scalar\n",
    "\n",
    "#             It represents the size of feature space, feature dimension\n",
    "\n",
    "#         cluster_mean: an array\n",
    "\n",
    "#             It holds two-element arrays as means for individual clusters in a dataset\n",
    "\n",
    "#         cluster_cov: an array \n",
    "\n",
    "#             It holds 2 dimensional arrays as the covarance matrices of individual clusters in a dataset\n",
    "\n",
    "#         overlap: a scalar\n",
    "\n",
    "#             It represents how close the clusters are from each other. Small value \n",
    "#             makes them come close to each other and higher value >= 1 puts them \n",
    "#             farther apart from each other.\n",
    "\n",
    "#         n_seed: an integer\n",
    "\n",
    "#             It is used to generate the same samples\n",
    "            \n",
    "#     return_dataset_properties: a boolean \n",
    "    \n",
    "#         If it is True the function returns data and the input dictionary else it only return data. \n",
    "            \n",
    "            \n",
    "# Example of para:\n",
    "            \n",
    "#             dataset_para = {'n_clusters': 2,\n",
    "#                             'n_sample': [5, 5], \n",
    "#                             'n_feature': 2, \n",
    "#                             'cluster_mean': np.array([[-4, 3], [4,-5]]), \n",
    "#                             'cluster_cov': np.array([[[1,0], \n",
    "#                                                       [0,1]],\n",
    "#                                                       [[1,0], \n",
    "#                                                        [0,1]]\n",
    "#                                                     ]),\n",
    "#                             'overlap': 1,  \n",
    "#                             'n_seed':seed_num\n",
    "#                             }\n",
    "        \n",
    "        \n",
    "#     Return:\n",
    "#     ------\n",
    "    \n",
    "#     D: a tuple\n",
    "    \n",
    "#         The first element, X, is a 2 dimensional array of shape (n_samples, n_attributes) which contains the \n",
    "#         bivariate normally distributed random numbers and the second element, y, is a one dimensional array \n",
    "#         of shape (n_samples) representing the cluster labels of individual points. \n",
    "    \n",
    "#     para: a dictionary\n",
    "    \n",
    "#         It is the same as input para\n",
    "        \n",
    "#     \"\"\"\n",
    "#     # reset the seed\n",
    "#     np.random.seed(seed_num) \n",
    "    \n",
    "    \n",
    "#     # create cluster one at a time\n",
    "#     for c_num in range(para['n_clusters']):\n",
    "                      \n",
    "#         features = np.random.multivariate_normal(mean=para['cluster_mean'][c_num]*para['overlap'], \n",
    "#                                                  cov=para['cluster_cov'][c_num],\n",
    "#                                                  size=para['n_sample'][c_num])\n",
    "\n",
    "#         label = np.repeat(a=c_num, repeats=para['n_sample'][c_num])\n",
    "        \n",
    "#         # concatinate data with labels\n",
    "#         if c_num == 0:\n",
    "#             X = features\n",
    "#             y = label\n",
    "#         else:\n",
    "#             X = np.concatenate((X, features), axis=0)\n",
    "#             y = np.concatenate((y, label), axis = 0)\n",
    "            \n",
    "\n",
    "            \n",
    "#     # shuffle data \n",
    "#     n_row, n_column = X.shape    \n",
    "#     shuffle_index = np.random.choice(range(0, n_row), size=n_row, replace=False) \n",
    "#     X = X[shuffle_index,:]\n",
    "#     y = y[shuffle_index,]\n",
    "    \n",
    "#     D = X,y \n",
    "    \n",
    "    \n",
    "#     # return properties if properties is True\n",
    "#     if return_dataset_properties:\n",
    "#         return D, para\n",
    "#     else:    \n",
    "#         return D\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "def draw_bivariate_normal(n_samples, mu=[0,0], std=[1,1], xy_scaling=(1,1), rotation_angle=0, n_seed = 0):\n",
    "    \"\"\"\n",
    "    Return bivariate normally distributed data points with given mean and standard deviation.\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "#     np.random.seed(n_seed)\n",
    "    # Normal distributed x and y vector with mean 0 and standard deviation 1    \n",
    "    x = np.random.normal(loc = mu[0], scale = std[0], size = n_samples)\n",
    "    y = np.random.normal(loc= mu[1], scale = std[1] , size = n_samples)\n",
    "    \n",
    "    # stack features x and y horizontally \n",
    "    X = np.vstack((x,y)).T\n",
    "    \n",
    "    # linear transformation of data\n",
    "    # scale each features independently\n",
    "    sx, sy = xy_scaling\n",
    "    Scale = np.array([[sx, 0], [0, sy]])\n",
    "    \n",
    "    # rotate data with a certain angle\n",
    "    # Rotation matrix\n",
    "    theta = rotation_angle # 0.25*np.pi\n",
    "    c, s = np.cos(theta), np.sin(theta)\n",
    "    Rot = np.array([[c, -s], [s, c]])\n",
    "\n",
    "    # Transformation matrix\n",
    "    T = Scale.dot(Rot)\n",
    "    \n",
    "    # Center the matrix at the origin\n",
    "    mus = np.mean(X, 0)\n",
    "    X = X - mus\n",
    "\n",
    "    # Apply transformation matrix to X\n",
    "    Y = X.dot(T)\n",
    "\n",
    "    # put back to original location\n",
    "    Y = Y + mus\n",
    "#     D = X, y\n",
    "    \n",
    "    \n",
    "    return Y\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "def create_multiclass_bivariate_data(data_params, reset_seed = False):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Return bivariate normally distributed data points with specified mean and standard deviation for each cluster\n",
    "    and crossponding cluster labels.\n",
    "    \n",
    "    Parameter:\n",
    "    ---------\n",
    "    \n",
    "    data_params: a dictionary\n",
    "        It holds the statistical parameters of dataset being generated. \n",
    "        \n",
    "        Example:\n",
    "        \n",
    "        n_clusters = 2\n",
    "        n_point = 50\n",
    "        overlap = 1\n",
    "        seed_number = 1234567890\n",
    "\n",
    "        data_params = {     'cluster_sample_sizes':np.array([n_point]*n_clusters),\n",
    "                             'cluster_nums':n_clusters,\n",
    "                             'cluster_means': np.array([[0,0], [6,0]\n",
    "                                                       ])*overlap,\n",
    "                             'cluster_stds': np.array([[0.7, 0.1], [0.5,1]\n",
    "                                                      ]),\n",
    "                              'cluster_xy_scalings': np.array([(1, 1), (1, 1)]), # value < 1 shrinks x or y and value > 1 expand \n",
    "                              'cluster_rotation_angles': np.array([np.pi/4, 0]), # angles in radians +ve value anticlockwise -ve slope) and vice-versa\n",
    "                              'cluster_seed_numbers': seed_number,\n",
    "                              'cluster_overlaps': overlap,\n",
    "\n",
    "                             }\n",
    "                             \n",
    "    reset_seed: a bool\n",
    "        It denotes whether or not to reset random seed before generating random samples.\n",
    "        \n",
    "    \n",
    "    Return:\n",
    "    ------\n",
    "    \n",
    "    D: a tuple\n",
    "    \n",
    "        The first element, X, is a 2 dimensional array of shape (n_samples, n_attributes) which contains the \n",
    "        bivariate normally distributed random numbers and the second element, cluster_label, is a one dimensional array \n",
    "        of shape (n_samples) representing the cluster labels of individual points. \n",
    "    \n",
    "    \"\"\"\n",
    "    if reset_seed:\n",
    "        np.random.seed(data_params['cluster_seed_numbers'])\n",
    "    \n",
    "    # draw bivariate samples for each class one at a time and stack in the data matrix X and cluster label \n",
    "    \n",
    "    for c_num, c_size in enumerate(data_params['cluster_sample_sizes']):\n",
    "        \n",
    "        features = draw_bivariate_normal(n_samples = c_size,\n",
    "                                         mu = data_params['cluster_means'][c_num]*data_params['cluster_overlaps'],\n",
    "                                         std = data_params['cluster_stds'][c_num],\n",
    "                                         xy_scaling = data_params['cluster_xy_scalings'][c_num],\n",
    "                                         rotation_angle = data_params['cluster_rotation_angles'][c_num]\n",
    "#                                                 n_seed = data_params['cluster_seed_numbers']\n",
    "                                        )\n",
    "        # create label\n",
    "        label = np.repeat(a=c_num, repeats=c_size)\n",
    "        \n",
    "        if c_num == 0:\n",
    "            X = features\n",
    "            cluster_label = label\n",
    "        else:\n",
    "            X = np.concatenate((X, features), axis = 0)\n",
    "            cluster_label = np.concatenate((cluster_label, label), axis = 0)\n",
    "    \n",
    "    # shuffle data points\n",
    "    n_row, n_column = X.shape    \n",
    "    shuffle_index = np.random.choice(range(0, n_row), size=n_row, replace=False) \n",
    "    \n",
    "    X = X[shuffle_index,:]\n",
    "    cluster_label = cluster_label[shuffle_index,]\n",
    "    \n",
    "    D = X, cluster_label           \n",
    "        \n",
    "        \n",
    "    return  D\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "def create_square_cluster(cluster_size, reset_seed = False):\n",
    "    ''' \n",
    "    Return two dimensional features that have square clusters in it.\n",
    "    \n",
    "    Parameter\n",
    "    ---------\n",
    "    \n",
    "    cluster_size: a list of integers\n",
    "        The elements in the list represent the sample size of the respective clusters.\n",
    "        \n",
    "    reset_seed: a boolean\n",
    "        It denotes whether the seed is reset before drawing samples from the uniform distribution.\n",
    "    \n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    \n",
    "     D: a tuple\n",
    "    \n",
    "        The first element, X, is a 2 dimensional array of shape (n_samples, n_attributes) which contains the \n",
    "        bivariate normally distributed random numbers and the second element, cluster_label, is a one dimensional array \n",
    "        of shape (n_samples) representing the cluster labels of individual points. \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    if reset_seed:\n",
    "        np.random.seed(seed=seed_num)\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "\n",
    "    for i, c_size in enumerate(cluster_size):\n",
    "        if i == 0:\n",
    "            features = np.random.uniform(low=-2.0, high=0, size=(c_size, 2))\n",
    "            label = np.repeat(a = i, repeats=c_size)\n",
    "            X = features\n",
    "            y = label\n",
    "        \n",
    "                        \n",
    "        elif  i == 1:\n",
    "            features = np.random.uniform(low=0.5, high=2.5, size=(c_size, 2))\n",
    "            # shift the feature to the right\n",
    "            features[:, 1] = features[:, 1] - 2.5 \n",
    "            \n",
    "        elif i == 2:\n",
    "            features = np.random.uniform(low=0.2, high=2.2, size=(c_size, 2))\n",
    "            # shift the feature to the right\n",
    "            features[:, 0] = features[:, 0] + 1.5\n",
    "            \n",
    "        elif i == 3:            \n",
    "            features = np.random.uniform(low=-1, high=1, size=(c_size, 2))\n",
    "            # shift the feature to up\n",
    "            features[:, 1] = features[:, 1] + 1.2\n",
    "            \n",
    "        if i !=0:\n",
    "            label = np.repeat(a = i, repeats=c_size)        \n",
    "            X = np.concatenate((X, features), axis=0)\n",
    "            y = np.concatenate((y,label), axis=0)\n",
    "          \n",
    " \n",
    "    shuffle_index = np.random.choice(range(X.shape[0]), size= X.shape[0], replace=False)\n",
    "\n",
    "    X = X[shuffle_index,:]\n",
    "    y = y[shuffle_index,]\n",
    "   \n",
    "    D = X, y\n",
    "        \n",
    "    return  D\n",
    "# -----------------------------------------------------------------\n",
    "def create_3or4d_dataset(param, reset_seed=True, shuffle_col = False):\n",
    "    \"\"\" Return a 3 or 4 dimensional data array that are normally distributed using make_blobs \n",
    "    function from sklearn module and a one dimensional label array.  \n",
    "    Parameters:\n",
    "    -----------    \n",
    "    param: a dictionary\n",
    "         It contains the parameters of 3 or 4 dimensional dataset. A typical example\n",
    "         of param is shown below. \n",
    "         \n",
    "         Example: \n",
    "         \n",
    "         para_4d_dataset = {'n_samples': [100, 100], 'n_features': 4,\n",
    "        'centers' :np.array([[4, 3], [4, -3]]), 'repeated': 1, 'lin_combination': 0\n",
    "         'noise_sd': 1\n",
    "         \n",
    "    reset_seed: a boolean\n",
    "        if reset_seed = True, either the same colum is repeated or the same \n",
    "        gaussain noise is generated for the fourth column.   \n",
    "        \n",
    "    shuffle_col: a boolean\n",
    "        If true it will shuffle columns in the dataset  \n",
    "        \n",
    "    Return\n",
    "    ------    \n",
    "     X,y: a tuple\n",
    "    \n",
    "    The first element, X, is a 4 dimensional array of shape \n",
    "    (n_samples, n_attributes) which contains the \n",
    "     bivariate normally distributed random numbers and the second \n",
    "    element, y, is a one dimensional array of shape (n_samples) \n",
    "    representing the cluster labels of individual points.\n",
    "    \"\"\"\n",
    "    num_features = param['n_features']     \n",
    "    if reset_seed:\n",
    "        X, y = datasets.make_blobs(n_samples=param['n_samples'],\n",
    "        n_features=param['n_features'] - 1, centers = param['centers'],\n",
    "        shuffle = True, random_state = seed_num)\n",
    "    else:\n",
    "        X, y = datasets.make_blobs(n_samples=param['n_samples'],\n",
    "        n_features=param['n_features'] - 1, centers = param['centers'],\n",
    "        shuffle = True)\n",
    "    # add remaining feature dimensions by repeating one of the feature vectors of X randomly  \n",
    "    if param['repeated'] == 1:\n",
    "        if reset_seed:\n",
    "            # reset the random number generator\n",
    "            rng = RandomState(seed_num)\n",
    "            rep_col = rng.choice(range(X.shape[1]), size=1, replace=False)[0]    \n",
    "        else:\n",
    "            rep_col = np.random.choice(range(X.shape[1]), size=1, replace=False)[0] \n",
    "            \n",
    "        for col in range(param['n_features'] - 1,  param['n_features'] - 1 + param['repeated']):\n",
    "            X = np.concatenate((X, np.reshape(X[:, rep_col], (X.shape[0], 1))), axis = 1)\n",
    "    # add linear combination of columns of the data matrix X\n",
    "    if param['lin_combination'] == 1:\n",
    "        lin_sum = np.reshape(np.sum(X, axis=1), (X.shape[0], 1))\n",
    "        X = np.concatenate((X, lin_sum), axis = 1)\n",
    "    # add random noise vector \n",
    "    if param['repeated'] + param['lin_combination'] == 0:\n",
    "        if reset_seed:\n",
    "            rng = RandomState(seed_num)\n",
    "            gaussian_noise = np.reshape(param['noise_sd']*rng.randn(X.shape[0]), (X.shape[0], 1))\n",
    "        else:\n",
    "            gaussian_noise = np.reshape(param['noise_sd']*np.random.randn(X.shape[0]), (X.shape[0], 1))\n",
    "        X = np.concatenate((X, gaussian_noise), axis = 1)\n",
    "    # shuffle columns after creating 3rd or 4th column\n",
    "    if shuffle_col:        \n",
    "        shuffled_comumn_index = np.random.choice(list(range(X.shape[1])), size = X.shape[1], replace=False)\n",
    "        X = X[:, shuffled_comumn_index]    \n",
    "    return X, y\n",
    "# -----------------------------------------------------------------\n",
    "def create_highDimensional_dataset(data_para, reset_seed = True):\n",
    "    \"\"\" Return a high dimensional dataset using make_classification function \n",
    "    from sklearn modul.    \n",
    "    Parameters:\n",
    "    -----------    \n",
    "    data_para: a dictionary\n",
    "         It contains the parameters of multi-dimensional dataset.\n",
    "         A typical example of mulit-dimensional dataset:\n",
    "    \n",
    "        data_para = { 'n_samples': 600,'n_features': 5,'n_informative': 3,\n",
    "        'n_redundant': 1,'n_repeated': 1, 'n_classes': 3, 'class_sep': 3}\n",
    "       \n",
    "    reset_seed: a boolean\n",
    "        if reset_seed = True, either the same colum is repeated or the same \n",
    "        gaussain noise is generated for the fourth column.\n",
    "    \n",
    "    Return\n",
    "    ------    \n",
    "     data,label: a tuple    \n",
    "        The first element, data, is a multi dimensional array of shape \n",
    "        (n_samples, n_attributes) which contains the bivariate normally distributed \n",
    "        random numbers and the second element, label, is a one dimensional array \n",
    "        of shape (n_samples) representing the cluster labels of individual points. \n",
    "    \"\"\"\n",
    "    if reset_seed:\n",
    "        data, label = datasets.make_classification(n_samples=data_para['n_samples'],\n",
    "        n_features=data_para['n_features'], n_informative=data_para['n_informative'],\n",
    "        n_redundant=data_para['n_redundant'], n_repeated=data_para['n_repeated'],\n",
    "        n_classes=data_para['n_classes'], n_clusters_per_class=1,\n",
    "        weights = None, flip_y = 0.0, class_sep = data_para['class_sep'], \n",
    "        hypercube =True, shift = 0.0, scale = 1.0, shuffle = True, random_state = seed_num)        \n",
    "    else:\n",
    "        data, label = datasets.make_classification(n_samples=data_para['n_samples'],\n",
    "        n_features=data_para['n_features'], n_informative=data_para['n_informative'],\n",
    "        n_redundant=data_para['n_redundant'], n_repeated=data_para['n_repeated'],\n",
    "        n_classes=data_para['n_classes'], n_clusters_per_class=1,\n",
    "        weights = None, flip_y = 0.0, class_sep = data_para['class_sep'], \n",
    "        hypercube =True, shift = 0.0, scale = 1.0, shuffle = True)        \n",
    "    return data, label\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
